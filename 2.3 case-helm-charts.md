helm create chartmuseum

[root@fintest chartmuseum]# pwd
/root/k8s/helm-charts/chartmuseum
[root@fintest chartmuseum]# tree ./
./
├── charts
├── Chart.yaml
├── templates
│   ├── configmap.yaml
│   ├── deployment.yaml
│   ├── _helpers.tpl
│   ├── hpa.yaml
│   ├── ingress.yaml
│   ├── NOTES.txt
│   ├── pvc.yaml
│   ├── serviceaccount.yaml
│   ├── service.yaml
│   └── tests
│       └── test-connection.yaml
└── values.yaml

3 directories, 12 files
[root@fintest chartmuseum]# 

[root@fintest chartmuseum]# cat values.yaml 
# Default values for chartmuseum.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: chartmuseum/chartmuseum
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "edge"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

containers:
  env:
    chart_storage_key: chart.storage
    chart_storage_localdir_key: chart.storage_localdir
    chart_storage: local
    chart_storage_localdir: /charts
    env2: STORAGE_LOCAL_ROOTDIR
    env1: STORAGE
  ports:
    containerPort: 8080
  volumeMounts:
    volumename: local-chart-pv01
    mountPath: /charts

externalStorageclass:
  nfs_storage: "nfs-storage-aliyun-inter-localhost"
  spec:
    accessModes: ReadWriteMany
    resources:
      requests:
        storage: 10Gi

serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP
  port: 8080

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths: []
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}
[root@fintest chartmuseum]# cat templates/pvc.yaml 
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: {{ .Release.Name }}-pvc 
  labels:
    storage: {{ .Release.Name }}-pvc
  annotations:
    volume.beta.kubernetes.io/storage-class: {{ .Values.externalStorageclass.nfs_storage }}
spec:
  accessModes:
  - {{ .Values.externalStorageclass.spec.accessModes }} 
  resources:
    requests:
      storage: {{ .Values.externalStorageclass.spec.resources.requests.storage }}
[root@fintest chartmuseum]# cat templates/configmap.yaml 
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-cm
  namespace: default
data:
  {{ .Values.containers.env.chart_storage_key }}: {{ .Values.containers.env.chart_storage }}
  {{ .Values.containers.env.chart_storage_localdir_key }}: {{ .Values.containers.env.chart_storage_localdir }} 
[root@fintest chartmuseum]# cat templates/deployment.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "chartmuseum.fullname" . }}
  labels:
    {{- include "chartmuseum.labels" . | nindent 4 }}
spec:
  {{- if not .Values.autoscaling.enabled }}
  replicas: {{ .Values.replicaCount }}
  {{- end }}
  selector:
    matchLabels:
      {{- include "chartmuseum.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      {{- with .Values.podAnnotations }}
      annotations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:
        {{- include "chartmuseum.selectorLabels" . | nindent 8 }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "chartmuseum.serviceAccountName" . }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      containers:
        - name: {{ .Chart.Name }}
          securityContext:
            {{- toYaml .Values.securityContext | nindent 12 }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          env:
            - name: {{ .Values.containers.env.env1 }}
              valueFrom:
                configMapKeyRef:
                  name:  {{ .Release.Name }}-cm
                  key: {{ .Values.containers.env.chart_storage_key}}
            - name: {{ .Values.containers.env.env2 }}
              valueFrom:
                configMapKeyRef:
                  name:  {{ .Release.Name }}-cm
                  key: {{ .Values.containers.env.chart_storage_localdir_key }}
          ports:
            - name: http
              containerPort: {{ .Values.containers.ports.containerPort }}
              protocol: TCP
          volumeMounts:
          - name: {{ .Values.containers.volumeMounts.volumename }}
            mountPath: {{ .Values.containers.volumeMounts.mountPath }}
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /
              port: http
          resources:
            {{- toYaml .Values.resources | nindent 12 }}
      volumes:
      - name: {{ .Values.containers.volumeMounts.volumename }}
        persistentVolumeClaim:
          claimName: {{ .Release.Name }}-pvc
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
[root@fintest chartmuseum]# cat templates/service.yaml 
apiVersion: v1
kind: Service
metadata:
  name: {{ include "chartmuseum.fullname" . }}
  labels:
    {{- include "chartmuseum.labels" . | nindent 4 }}
spec:
  type: {{ .Values.service.type }}
  ports:
    - port: {{ .Values.service.port }}
      targetPort: http
      protocol: TCP
      name: http
  selector:
    {{- include "chartmuseum.selectorLabels" . | nindent 4 }}
[root@fintest chartmuseum]# 


[root@fintest helm-charts]# helm install --dry-run --debug ./chartmuseum/ --generate-name
install.go:172: [debug] Original chart version: ""
install.go:189: [debug] CHART PATH: /root/k8s/helm-charts/chartmuseum

NAME: chartmuseum-1610595419
LAST DEPLOYED: Thu Jan 14 11:36:59 2021
NAMESPACE: default
STATUS: pending-install
REVISION: 1
USER-SUPPLIED VALUES:
{}

COMPUTED VALUES:
affinity: {}
autoscaling:
  enabled: false
  maxReplicas: 10
  minReplicas: 1
  targetCPUUtilizationPercentage: 80
containers:
  env:
    chart_storage: local
    chart_storage_key: chart.storage
    chart_storage_localdir: /charts
    chart_storage_localdir_key: chart.storage_localdir
    env1: STORAGE
    env2: STORAGE_LOCAL_ROOTDIR
  ports:
    containerPort: 8080
  volumeMounts:
    mountPath: /charts
    volumename: local-chart-pv01
externalStorageclass:
  nfs_storage: nfs-storage-aliyun-inter-localhost
  spec:
    accessModes: ReadWriteMany
    resources:
      requests:
        storage: 10Gi
fullnameOverride: ""
image:
  pullPolicy: IfNotPresent
  repository: chartmuseum/chartmuseum
  tag: edge
imagePullSecrets: []
ingress:
  annotations: {}
  enabled: false
  hosts:
  - host: chart-example.local
    paths: []
  tls: []
nameOverride: ""
nodeSelector: {}
podAnnotations: {}
podSecurityContext: {}
replicaCount: 1
resources: {}
securityContext: {}
service:
  port: 8080
  type: ClusterIP
serviceAccount:
  annotations: {}
  create: false
  name: ""
tolerations: []

HOOKS:
---
# Source: chartmuseum/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "chartmuseum-1610595419-test-connection"
  labels:
    helm.sh/chart: chartmuseum-0.1.0
    app.kubernetes.io/name: chartmuseum
    app.kubernetes.io/instance: chartmuseum-1610595419
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['chartmuseum-1610595419:8080']
  restartPolicy: Never
MANIFEST:
---
# Source: chartmuseum/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: chartmuseum-1610595419-cm
  namespace: default
data:
  chart.storage: local
  chart.storage_localdir: /charts
---
# Source: chartmuseum/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: chartmuseum-1610595419-pvc 
  labels:
    storage: chartmuseum-1610595419-pvc
  annotations:
    volume.beta.kubernetes.io/storage-class: nfs-storage-aliyun-inter-localhost
spec:
  accessModes:
  - ReadWriteMany 
  resources:
    requests:
      storage: 10Gi
---
# Source: chartmuseum/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: chartmuseum-1610595419
  labels:
    helm.sh/chart: chartmuseum-0.1.0
    app.kubernetes.io/name: chartmuseum
    app.kubernetes.io/instance: chartmuseum-1610595419
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: chartmuseum
    app.kubernetes.io/instance: chartmuseum-1610595419
---
# Source: chartmuseum/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: chartmuseum-1610595419
  labels:
    helm.sh/chart: chartmuseum-0.1.0
    app.kubernetes.io/name: chartmuseum
    app.kubernetes.io/instance: chartmuseum-1610595419
    app.kubernetes.io/version: "1.16.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: chartmuseum
      app.kubernetes.io/instance: chartmuseum-1610595419
  template:
    metadata:
      labels:
        app.kubernetes.io/name: chartmuseum
        app.kubernetes.io/instance: chartmuseum-1610595419
    spec:
      serviceAccountName: default
      securityContext:
        {}
      containers:
        - name: chartmuseum
          securityContext:
            {}
          image: "chartmuseum/chartmuseum:edge"
          imagePullPolicy: IfNotPresent
          env:
            - name: STORAGE
              valueFrom:
                configMapKeyRef:
                  name:  chartmuseum-1610595419-cm
                  key: chart.storage
            - name: STORAGE_LOCAL_ROOTDIR
              valueFrom:
                configMapKeyRef:
                  name:  chartmuseum-1610595419-cm
                  key: chart.storage_localdir
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          volumeMounts:
          - name: local-chart-pv01
            mountPath: /charts
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /
              port: http
          resources:
            {}
      volumes:
      - name: local-chart-pv01
        persistentVolumeClaim:
          claimName: chartmuseum-1610595419-pvc

NOTES:
1. Get the application URL by running these commands:
  export POD_NAME=$(kubectl get pods --namespace default -l "app.kubernetes.io/name=chartmuseum,app.kubernetes.io/instance=chartmuseum-1610595419" -o jsonpath="{.items[0].metadata.name}")
  export CONTAINER_PORT=$(kubectl get pod --namespace default $POD_NAME -o jsonpath="{.spec.containers[0].ports[0].containerPort}")
  echo "Visit http://127.0.0.1:8080 to use your application"
  kubectl --namespace default port-forward $POD_NAME 8080:$CONTAINER_PORT
[root@fintest helm-charts]# helm install ./chartmuseum/ --generate-name
NAME: chartmuseum-1610595572
LAST DEPLOYED: Thu Jan 14 11:39:32 2021
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
1. Get the application URL by running these commands:
  export POD_NAME=$(kubectl get pods --namespace default -l "app.kubernetes.io/name=chartmuseum,app.kubernetes.io/instance=chartmuseum-1610595572" -o jsonpath="{.items[0].metadata.name}")
  export CONTAINER_PORT=$(kubectl get pod --namespace default $POD_NAME -o jsonpath="{.spec.containers[0].ports[0].containerPort}")
  echo "Visit http://127.0.0.1:8080 to use your application"
  kubectl --namespace default port-forward $POD_NAME 8080:$CONTAINER_PORT
[root@fintest helm-charts]# kubectl get svc
NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
chartmuseum-1610595572   ClusterIP   10.98.39.48     <none>        8080/TCP         11s
kubernetes               ClusterIP   10.96.0.1       <none>        443/TCP          2d18h
local-chart-svc          NodePort    10.102.176.74   <none>        8080:30020/TCP   18h
[root@fintest helm-charts]# kubectl get deploy
NAME                     READY   UP-TO-DATE   AVAILABLE   AGE
chartmuseum-1610595572   1/1     1            1           19s
local-chart-deploy       1/1     1            1           18h
nfs-client-provisioner   1/1     1            1           2d15h
[root@fintest helm-charts]# kubectl get pod
NAME                                      READY   STATUS    RESTARTS   AGE
chartmuseum-1610595572-78f59c8497-bhcrw   1/1     Running   0          25s
local-chart-deploy-84d9fd5cfb-f84w8       1/1     Running   0          18h
nfs-client-provisioner-dd4799dfb-wmgfs    1/1     Running   0          2d15h
[root@fintest helm-charts]# kubectl get pvc
NAME                         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS                         AGE
chartmuseum-1610595572-pvc   Bound    pvc-66c52e98-8e7c-4530-9bf4-a3ca67e9dce3   10Gi       RWX            nfs-storage-aliyun-inter-localhost   35s
local-chart-pvc              Bound    pvc-2b67ebba-2bd4-49cb-98eb-428b09abe268   10Gi       RWX            nfs-storage-aliyun-inter-localhost   19h
[root@fintest helm-charts]# kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                STORAGECLASS                         REASON   AGE
pvc-2b67ebba-2bd4-49cb-98eb-428b09abe268   10Gi       RWX            Delete           Bound    default/local-chart-pvc              nfs-storage-aliyun-inter-localhost            19h
pvc-66c52e98-8e7c-4530-9bf4-a3ca67e9dce3   10Gi       RWX            Delete           Bound    default/chartmuseum-1610595572-pvc   nfs-storage-aliyun-inter-localhost            38s
[root@fintest helm-charts]# kubectl get svc
NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
chartmuseum-1610595572   ClusterIP   10.98.39.48     <none>        8080/TCP         61s
kubernetes               ClusterIP   10.96.0.1       <none>        443/TCP          2d18h
local-chart-svc          NodePort    10.102.176.74   <none>        8080:30020/TCP   18h
[root@fintest helm-charts]# curl http://10.98.39.48:8080
<!DOCTYPE html>
<html>
<head>
<title>Welcome to ChartMuseum!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
<body>
<h1>Welcome to ChartMuseum!</h1>
<p>If you see this page, the ChartMuseum web server is successfully installed and
working.</p>

<p>For online documentation and support please refer to the
<a href="https://github.com/helm/chartmuseum">GitHub project</a>.<br/>

<p><em>Thank you for using ChartMuseum.</em></p>
</body>
</html>
[root@fintest helm-charts]# 
        
